{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "820180e2-6717-46bd-b7a6-bd40bf26fe8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Start: PixelHop_Unit\n",
      "------------------- Start: PixelHop_8_Neighbour\n",
      "       <Info>        Input feature shape: (1000, 32, 32, 1)\n",
      "       <Info>        dilate: 1\n",
      "       <Info>        padding: reflect\n",
      "       <Info>        Output feature shape: (1000, 32, 32, 9)\n",
      "------------------- End: PixelHop_8_Neighbour -> using   0.039000 seconds\n",
      "------------------- Start: Saab transformation\n",
      "       <Info>        pixelhop_feature.shape: (1000, 32, 32, 9)\n",
      "       <Info>        training_data.shape: (1024000, 9)\n",
      "       <Info>        Num of kernels: 5\n",
      "       <Info>        Energy percent: 0.941525\n",
      "       <Info>        Sample patches shape after flatten: (1024000, 9)\n",
      "       <Info>        Kernel shape: (5, 9)\n",
      "       <Info>        Transformed shape: (1024000, 5)\n",
      "       <Info>        Save pca params as name: ../weight/pixelhop1_mnist.pkl\n",
      "------------------- End: Saab transformation -> using   0.413373 seconds\n",
      "------------------- Start: Pixelhop_fit\n",
      "       <Info>        Using weight: ../weight/pixelhop1_mnist.pkl\n",
      "       <Info>        Transformed feature shape: (1000, 32, 32, 5)\n",
      "------------------- End: Pixelhop_fit -> using   0.053999 seconds\n",
      "       <Info>        Output feature shape: (1000, 32, 32, 5)\n",
      "=========== End: PixelHop_Unit -> using   0.511372 seconds\n",
      "--------Train LAG Unit--------\n",
      "feature_train shape: (1000, 320)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoyo2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISH KMEANS 0\n",
      "FINISH KMEANS 1\n",
      "FINISH KMEANS 2\n",
      "FINISH KMEANS 3\n",
      "FINISH KMEANS 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoyo2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n",
      "C:\\Users\\yoyo2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n",
      "C:\\Users\\yoyo2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n",
      "C:\\Users\\yoyo2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n",
      "C:\\Users\\yoyo2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISH KMEANS 5\n",
      "FINISH KMEANS 6\n",
      "FINISH KMEANS 7\n",
      "FINISH KMEANS 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoyo2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n",
      "C:\\Users\\yoyo2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n",
      "C:\\Users\\yoyo2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n",
      "C:\\Users\\yoyo2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISH KMEANS 9\n",
      "Alpha: 5\n",
      "weight (320, 50)\n",
      "bias (1, 50)\n",
      "0  Kmean training acc is: 0.938\n",
      "=========== Start: PixelHop_Unit\n",
      "------------------- Start: PixelHop_8_Neighbour\n",
      "       <Info>        Input feature shape: (500, 32, 32, 1)\n",
      "       <Info>        dilate: 1\n",
      "       <Info>        padding: reflect\n",
      "       <Info>        Output feature shape: (500, 32, 32, 9)\n",
      "------------------- End: PixelHop_8_Neighbour -> using   0.024999 seconds\n",
      "------------------- Start: Pixelhop_fit\n",
      "       <Info>        Using weight: ../weight/pixelhop1_mnist.pkl\n",
      "       <Info>        Transformed feature shape: (500, 32, 32, 5)\n",
      "------------------- End: Pixelhop_fit -> using   0.020000 seconds\n",
      "       <Info>        Output feature shape: (500, 32, 32, 5)\n",
      "=========== End: PixelHop_Unit -> using   0.047999 seconds\n",
      "--------Testing--------\n",
      "***** Train ACC: 0.994\n",
      "***** Test ACC: 0.996\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import time\n",
    "from framework.layer import *\n",
    "from framework.utli import *\n",
    "from framework.pixelhop import *\n",
    "from framework.data import *\n",
    "from framework.LAG import LAG_Unit\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from skimage.measure import block_reduce\n",
    "\n",
    "def myModel(x, getK=1):\n",
    "    x1 = PixelHop_Unit(x, dilate=1, pad='reflect', num_AC_kernels=9, weight_name='pixelhop1.pkl', getK=getK)\n",
    "\n",
    "    x2 = PixelHop_Unit(x1, dilate=2, pad='reflect', num_AC_kernels=25, weight_name='pixelhop2.pkl', getK=getK)\n",
    "    x2 = AvgPooling(x2)\n",
    "\n",
    "    x3 = PixelHop_Unit(x2, dilate=2, pad='reflect', num_AC_kernels=35, weight_name='pixelhop3.pkl', getK=getK)\n",
    "    x3 = AvgPooling(x3)\n",
    "\n",
    "    x4 = PixelHop_Unit(x3, dilate=2, pad='reflect', num_AC_kernels=55, weight_name='pixelhop4.pkl', getK=getK)\n",
    "\n",
    "    x2 = myResize(x2, x.shape[1], x.shape[2])\n",
    "    x3 = myResize(x3, x.shape[1], x.shape[2])\n",
    "    x4 = myResize(x4, x.shape[1], x.shape[2])\n",
    "    return np.concatenate((x1,x2,x3,x4), axis=3)\n",
    "if False:\n",
    "    x = cv2.imread('../data/test.jpg')\n",
    "    x = x.reshape(1, x.shape[0], x.shape[1], -1)\n",
    "    feature = myModel(x, getK=1)\n",
    "if True:\n",
    "    train_images, train_labels, test_images, test_labels, class_list = import_data_mnist(\"0-9\")  \n",
    "    N_train=1000\n",
    "    N_test=500\n",
    "    SAVE={}\n",
    "    train_images=train_images[:N_train]\n",
    "    train_labels=train_labels[:N_train]\n",
    "    test_images=train_images[:N_test]\n",
    "    test_labels=train_labels[:N_test]\n",
    "    \n",
    "    train_feature=PixelHop_Unit(train_images, dilate=1, pad='reflect', num_AC_kernels=5, weight_name='pixelhop1_mnist.pkl', getK=1)\n",
    "    train_feature = block_reduce(train_feature, (1, 4, 4, 1), np.mean).reshape(N_train,-1)\n",
    "    train_feature_reduce=LAG_Unit(train_feature,train_labels=train_labels, class_list=class_list,\n",
    "                             SAVE=SAVE,num_clusters=50,alpha=5,Train=True)\n",
    "    \n",
    "    test_feature=PixelHop_Unit(test_images, dilate=1, pad='reflect', num_AC_kernels=5, weight_name='pixelhop1_mnist.pkl', getK=0)\n",
    "    test_feature=block_reduce(test_feature, (1, 4, 4, 1), np.mean).reshape(N_test,-1)\n",
    "    test_feature_reduce=LAG_Unit(test_feature,train_labels=None, class_list=class_list,\n",
    "                         SAVE=SAVE,num_clusters=50,alpha=5,Train=False)\n",
    "    \n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn import preprocessing\n",
    "    scaler=preprocessing.StandardScaler()\n",
    "    feature      = scaler.fit_transform(train_feature_reduce)\n",
    "    feature_test = scaler.transform(test_feature_reduce)     \n",
    "   \n",
    "    clf=SVC().fit(feature, train_labels) \n",
    "##        clf=RandomForestClassifier(n_estimators=500,max_depth=5).fit(train_f, train_labels) \n",
    "    print('***** Train ACC:', accuracy_score(train_labels,clf.predict(feature)))\n",
    "    print('***** Test ACC:', accuracy_score(test_labels,clf.predict(feature_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4bf23e-6acd-478d-a27c-1c0ffd42dccf",
   "metadata": {},
   "source": [
    "## 1. Model 輸入test_images[0:1]  ， 預測結果是數字5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1d2f954-9219-49b1-b479-4d08e5765936",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Start: PixelHop_Unit\n",
      "------------------- Start: PixelHop_8_Neighbour\n",
      "       <Info>        Input feature shape: (1, 32, 32, 1)\n",
      "       <Info>        dilate: 1\n",
      "       <Info>        padding: reflect\n",
      "       <Info>        Output feature shape: (1, 32, 32, 9)\n",
      "------------------- End: PixelHop_8_Neighbour -> using   0.014994 seconds\n",
      "------------------- Start: Pixelhop_fit\n",
      "       <Info>        Using weight: ../weight/pixelhop1_mnist.pkl\n",
      "       <Info>        Transformed feature shape: (1, 32, 32, 5)\n",
      "------------------- End: Pixelhop_fit -> using   0.000000 seconds\n",
      "       <Info>        Output feature shape: (1, 32, 32, 5)\n",
      "=========== End: PixelHop_Unit -> using   0.015997 seconds\n",
      "--------Testing--------\n",
      "model預測結果: [5]\n"
     ]
    }
   ],
   "source": [
    "test_feature=PixelHop_Unit(test_images[0:1], dilate=1, pad='reflect', num_AC_kernels=5, weight_name='pixelhop1_mnist.pkl', getK=0)\n",
    "test_feature=block_reduce(test_feature, (1, 4, 4, 1), np.mean).reshape(1,-1)\n",
    "test_feature_reduce=LAG_Unit(test_feature,train_labels=None, class_list=class_list,\n",
    "                     SAVE=SAVE,num_clusters=50,alpha=5,Train=False)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "scaler=preprocessing.StandardScaler()\n",
    "feature = scaler.fit_transform(train_feature_reduce)\n",
    "feature_test = scaler.transform(test_feature_reduce)        \n",
    "x=clf.predict(feature_test)\n",
    "print('model預測結果:',x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36ea291-9461-4084-83d6-f9a24c66d946",
   "metadata": {},
   "source": [
    "## 2. 請不使用 PixelHop_Unit 函數，也不依賴任何現成的模組，純粹使用數學矩陣運算來推導 PixelHop_Unit 的運作邏輯。具體地，實現從 test_images[0:1] 與 pixelhop1_mnist.pkl 文件中的權重出發，手動計算過程，並最終得到 test_feature(如以下輸出)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a04d4c02-380f-435a-9091-34505bf3f007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Start: PixelHop_Unit\n",
      "------------------- Start: PixelHop_8_Neighbour\n",
      "       <Info>        Input feature shape: (1, 32, 32, 1)\n",
      "       <Info>        dilate: 1\n",
      "       <Info>        padding: reflect\n",
      "       <Info>        Output feature shape: (1, 32, 32, 9)\n",
      "------------------- End: PixelHop_8_Neighbour -> using   0.013995 seconds\n",
      "------------------- Start: Pixelhop_fit\n",
      "       <Info>        Using weight: ../weight/pixelhop1_mnist.pkl\n",
      "       <Info>        Transformed feature shape: (1, 32, 32, 5)\n",
      "------------------- End: Pixelhop_fit -> using   0.000000 seconds\n",
      "       <Info>        Output feature shape: (1, 32, 32, 5)\n",
      "=========== End: PixelHop_Unit -> using   0.013995 seconds\n",
      "model輸出格式: (1, 32, 32, 5)\n",
      "model輸出: [[[[-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   ...\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]]\n",
      "\n",
      "  [[-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   ...\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]]\n",
      "\n",
      "  [[-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   ...\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   ...\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]]\n",
      "\n",
      "  [[-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   ...\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]]\n",
      "\n",
      "  [[-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   ...\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]]]]\n",
      "Feature shape: 1 32 32 1\n",
      "------------------- Start: PixelHop_8_Neighbour\n",
      "       <Info>        Input feature shape: 1\n",
      "       <Info>        dilate: 1\n",
      "       <Info>        padding: reflect\n",
      "       <Info>        Output feature shape: 1\n",
      "------------------- End: PixelHop_8_Neighbour -> using   0.008000 seconds\n",
      "Feature shape: 1 32 32 9\n",
      "------------------- Start: Pixelhop_fit\n",
      "       <Info>        Using weight: ../weight/pixelhop1_mnist.pkl\n",
      "       <Info>        Transformed feature shape: (1, 32, 32, 5)\n",
      "------------------- End: Pixelhop_fit -> using   0.000000 seconds\n",
      "model輸出格式: (1, 32, 32, 5)\n",
      "model輸出: [[[[-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   ...\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]]\n",
      "\n",
      "  [[-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   ...\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]]\n",
      "\n",
      "  [[-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   ...\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   ...\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]]\n",
      "\n",
      "  [[-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   ...\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]]\n",
      "\n",
      "  [[-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   ...\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]\n",
      "   [-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "    -1.04233547e-08]]]]\n"
     ]
    }
   ],
   "source": [
    "test_feature=PixelHop_Unit(test_images[0:1], dilate=1, pad='reflect', num_AC_kernels=5, weight_name='pixelhop1_mnist.pkl', getK=0)\n",
    "print('model輸出格式:',test_feature.shape)\n",
    "print('model輸出:',test_feature)\n",
    "\n",
    "def PixelHop_8_Neighbour(feature, dilate, pad):\n",
    "    \n",
    "    print(\"------------------- Start: PixelHop_8_Neighbour\")\n",
    "    print(\"       <Info>        Input feature shape: %s\" % str(len(feature)))\n",
    "    print(\"       <Info>        dilate: %s\" % str(dilate))\n",
    "    print(\"       <Info>        padding: %s\" % str(pad))\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Determine shape\n",
    "    batch_size = len(feature)\n",
    "    height = len(feature[0])\n",
    "    width = len(feature[0][0])\n",
    "    depth = len(feature[0][0][0])\n",
    "\n",
    "    # Apply padding\n",
    "    if pad == 'reflect':\n",
    "        padded_feature = []\n",
    "        for batch in feature:\n",
    "            padded_batch = []\n",
    "            for row in batch:\n",
    "                reflected_row = row[:dilate][::-1] + row + row[-dilate:][::-1]\n",
    "                padded_batch.append(reflected_row)\n",
    "            padded_batch = padded_batch[:dilate][::-1] + padded_batch + padded_batch[-dilate:][::-1]\n",
    "            padded_feature.append(padded_batch)\n",
    "    elif pad == 'zeros':\n",
    "        padded_feature = []\n",
    "        zero_row = [[0] * depth for _ in range(width + 2 * dilate)]\n",
    "        for batch in feature:\n",
    "            padded_batch = [zero_row[:] for _ in range(dilate)]\n",
    "            for row in batch:\n",
    "                padded_row = [[0] * depth] * dilate + row + [[0] * depth] * dilate\n",
    "                padded_batch.append(padded_row)\n",
    "            padded_batch.extend([zero_row[:] for _ in range(dilate)])\n",
    "            padded_feature.append(padded_batch)\n",
    "    else:  # pad == 'none'\n",
    "        padded_feature = feature\n",
    "\n",
    "    # Output shape\n",
    "    if pad == \"none\":\n",
    "        res = [[[[0] * (9 * depth) for _ in range(width - 2 * dilate)] for _ in range(height - 2 * dilate)] for _ in range(batch_size)]\n",
    "    else:\n",
    "        res = [[[[0] * (9 * depth) for _ in range(width)] for _ in range(height)] for _ in range(batch_size)]\n",
    "\n",
    "    # Extract 8 neighbors\n",
    "    idx = [-1, 0, 1]\n",
    "    for b in range(batch_size):\n",
    "        for i in range(dilate, len(padded_feature[b]) - dilate):\n",
    "            for j in range(dilate, len(padded_feature[b][i]) - dilate):\n",
    "                tmp = []\n",
    "                for ii in idx:\n",
    "                    for jj in idx:\n",
    "                        iii = i + ii * dilate\n",
    "                        jjj = j + jj * dilate\n",
    "                        tmp.extend(padded_feature[b][iii][jjj])\n",
    "                res[b][i - dilate][j - dilate] = tmp\n",
    "\n",
    "    print(\"       <Info>        Output feature shape: %s\" % str(len(res)))\n",
    "    print(\"------------------- End: PixelHop_8_Neighbour -> using %10f seconds\" % (time.time() - t0))\n",
    "    return res\n",
    "    \n",
    "    if pad == 'reflect':\n",
    "        feature = custom_padding(feature, dilate=dilate, pad_type='reflect')\n",
    "    elif pad == 'zeros':\n",
    "        feature = custom_padding(feature, dilate=dilate, pad_type='constant', constant_value=0)\n",
    "    if pad == \"none\":\n",
    "        res = custom_zeros(S[1]-2*dilate, S[2]-2*dilate, S[0], 9*S[3])\n",
    "    else:\n",
    "        res = custom_zeros(S[1], S[2], S[0], 9*S[3])\n",
    "        \n",
    "    def move_axis(feature, source, destination):\n",
    "        # 手動實現移動軸的功能\n",
    "        axes = list(range(len(feature)))\n",
    "        axes.pop(source)\n",
    "        axes.insert(destination, source)\n",
    "        return [[feature[j][i] for j in range(len(feature))] for i in range(len(feature[0]))]\n",
    "        \n",
    "    idx = [-1, 0, 1]\n",
    "    feature = move_axis(feature, 0, 2)  # 模擬 np.moveaxis 功能\n",
    "\n",
    "    # 初始化 res 為嵌套 list\n",
    "    height, width = len(feature), len(feature[0])\n",
    "    res = [[[0] * (S[0] * len(idx)**2) for _ in range(width - 2 * dilate)] for _ in range(height - 2 * dilate)]\n",
    "    \n",
    "    # 遍歷 feature，填充 res\n",
    "    for i in range(dilate, height - dilate):\n",
    "        for j in range(dilate, width - dilate):\n",
    "            tmp = []\n",
    "            for ii in idx:\n",
    "                for jj in idx:\n",
    "                    iii = i + ii * dilate\n",
    "                    jjj = j + jj * dilate\n",
    "                    tmp.append(feature[iii][jjj])\n",
    "\n",
    "            # 壓平和調整維度\n",
    "            flat_tmp = [item for sublist in tmp for item in sublist]\n",
    "            res[i - dilate][j - dilate] = flat_tmp[:S[0] * len(flat_tmp)]\n",
    "\n",
    "    return res\n",
    "    \n",
    "def Pixelhop_fit(weight_path, feature, useDC):\n",
    "    print(\"------------------- Start: Pixelhop_fit\")\n",
    "    print(\"       <Info>        Using weight: %s\"%str(weight_path))\n",
    "    t0 = time.time()\n",
    "    fr = open(weight_path, 'rb')\n",
    "    pca_params = pickle.load(fr)\n",
    "    fr.close()\n",
    "    weight = pca_params['Layer_0/kernel'].astype(np.float32)\n",
    "    bias = pca_params['Layer_%d/bias' % 0]\n",
    "    # Add bias\n",
    "    feature_w_bias = feature + 1 / np.sqrt(feature.shape[3]) * bias\n",
    "    # Transform to get data for the next stage\n",
    "    transformed_feature = np.matmul(feature_w_bias, np.transpose(weight))\n",
    "    if useDC == True:\n",
    "        e = np.zeros((1, weight.shape[0]))\n",
    "        e[0, 0] = 1\n",
    "        transformed_feature -= bias * e\n",
    "    print(\"       <Info>        Transformed feature shape: %s\"%str(transformed_feature.shape))\n",
    "    print(\"------------------- End: Pixelhop_fit -> using %10f seconds\"%(time.time()-t0))\n",
    "    return transformed_feature\n",
    "\n",
    "def PixelHop_Unit_manual(feature, dilate=1, num_AC_kernels=6, pad='reflect', weight_name='tmp.pkl', getK=False, useDC=False):\n",
    "    print(\"Feature shape:\", len(feature), len(feature[0]), len(feature[0][0]), len(feature[0][0][0]))\n",
    "    feature = PixelHop_8_Neighbour(feature, dilate, pad)\n",
    "    feature = np.array(feature)\n",
    "    print(\"Feature shape:\", len(feature), len(feature[0]), len(feature[0][0]), len(feature[0][0][0]))\n",
    "    if getK == True:\n",
    "        saab = Saab('../weight/'+weight_name, kernel_sizes=np.array([3]), num_kernels=np.array([num_AC_kernels]), useDC=useDC)\n",
    "        saab.fit(feature)\n",
    "    transformed_feature = Pixelhop_fit('../weight/'+weight_name, feature, useDC) \n",
    "    \n",
    "    return transformed_feature\n",
    "\n",
    "test_feature=PixelHop_Unit_manual(test_images[0:1], dilate=1, pad='reflect', num_AC_kernels=5, weight_name='pixelhop1_mnist.pkl', getK=0)\n",
    "print('model輸出格式:',test_feature.shape)\n",
    "print('model輸出:',test_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d959b4b7-cbc7-4050-b92c-600560d2a917",
   "metadata": {},
   "source": [
    "## 3.  請不使用 block_reduce 函數，也不依賴任何現成的模組，純粹使用數學矩陣運算來推導 block_reduce 的運作邏輯。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3f08f6f-ab9a-4882-8fb4-c2f9d22df047",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_reduce輸出格式: (1, 320)\n",
      "block_reduce輸出: [[-1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "  -1.04233547e-08 -1.05791576e-08 -1.47213662e-08  7.25102933e-09\n",
      "   7.25102938e-09 -1.04233547e-08 -1.05791576e-08 -1.47213662e-08\n",
      "   7.25102933e-09  7.25102938e-09 -1.04233547e-08 -1.05791576e-08\n",
      "  -1.47213662e-08  7.25102933e-09  7.25102938e-09 -1.04233547e-08\n",
      "  -1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "  -1.04233547e-08 -1.05791576e-08 -1.47213662e-08  7.25102933e-09\n",
      "   7.25102938e-09 -1.04233547e-08 -1.05791576e-08 -1.47213662e-08\n",
      "   7.25102933e-09  7.25102938e-09 -1.04233547e-08 -1.05791576e-08\n",
      "  -1.47213662e-08  7.25102933e-09  7.25102938e-09 -1.04233547e-08\n",
      "  -1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "  -1.04233547e-08 -1.05791576e-08 -1.47213662e-08  7.25102933e-09\n",
      "   7.25102938e-09 -1.04233547e-08 -5.32693752e-02  2.23814107e-02\n",
      "  -3.76904992e-02 -1.81047631e-02  1.13789192e-02 -1.97737310e-01\n",
      "   1.62163001e-01 -7.37051873e-02 -1.11572866e-01  3.49940187e-02\n",
      "  -3.00915833e-01  2.82466505e-01 -3.00065608e-02 -8.73656718e-02\n",
      "   3.61306379e-02 -3.33887247e-01  3.19569541e-01 -1.11318876e-02\n",
      "  -2.00295496e-02  5.71789170e-03  1.79750854e-02  1.28991778e-01\n",
      "   6.38245348e-02 -1.87912938e-02 -4.64091105e-02 -1.05791576e-08\n",
      "  -1.47213662e-08  7.25102933e-09  7.25102938e-09 -1.04233547e-08\n",
      "  -1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "  -1.04233547e-08 -1.44685058e-02 -1.38650700e-02 -4.04758948e-03\n",
      "  -2.97970655e-04 -1.08398582e-02 -3.60931885e-01 -2.31019725e-01\n",
      "  -7.86853068e-03  9.27168529e-02 -2.25962865e-02 -7.60723798e-03\n",
      "   1.05061019e-01  1.54324356e-01  1.26548862e-01 -2.31980392e-02\n",
      "   4.02750132e-01 -1.01808710e-01  5.38380240e-02  1.20094407e-01\n",
      "  -1.11936185e-02  3.55697933e-01 -2.98668532e-01  1.57836246e-02\n",
      "   2.03720230e-02  6.73981253e-03  1.27141736e-01  1.00726002e-02\n",
      "  -8.13439580e-02  1.75015566e-02 -5.09693305e-04 -1.05791576e-08\n",
      "  -1.47213662e-08  7.25102933e-09  7.25102938e-09 -1.04233547e-08\n",
      "  -1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "  -1.04233547e-08 -1.05791576e-08 -1.47213662e-08  7.25102933e-09\n",
      "   7.25102938e-09 -1.04233547e-08  1.29704172e-02 -1.75858313e-01\n",
      "   1.88569882e-02 -7.65778292e-02 -6.02932571e-02  3.84263294e-02\n",
      "  -9.36052450e-02 -1.26873429e-01  5.15543866e-02  1.23464486e-01\n",
      "  -4.46984126e-02  2.58843666e-01  5.29905071e-02 -1.26068359e-01\n",
      "  -3.60263837e-02  9.60416941e-05  3.45164643e-03  1.80016175e-03\n",
      "  -2.42672994e-03 -2.05738161e-03 -1.05791576e-08 -1.47213662e-08\n",
      "   7.25102933e-09  7.25102938e-09 -1.04233547e-08 -1.05791576e-08\n",
      "  -1.47213662e-08  7.25102933e-09  7.25102938e-09 -1.04233547e-08\n",
      "  -1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "  -1.04233547e-08 -1.05791576e-08 -1.47213662e-08  7.25102933e-09\n",
      "   7.25102938e-09 -1.04233547e-08 -1.05791576e-08 -1.47213662e-08\n",
      "   7.25102933e-09  7.25102938e-09 -1.04233547e-08 -1.31224128e-02\n",
      "  -3.16602442e-01  5.22110794e-02 -6.84362319e-02 -4.93692783e-02\n",
      "  -1.50873772e-01  1.34112927e-03 -1.48070835e-01  8.53724923e-02\n",
      "   1.26442154e-01  1.33524124e-01  3.47409453e-01  9.26136327e-02\n",
      "  -2.62990796e-02 -7.55428813e-02 -1.05791576e-08 -1.47213662e-08\n",
      "   7.25102933e-09  7.25102938e-09 -1.04233547e-08 -1.05791576e-08\n",
      "  -1.47213662e-08  7.25102933e-09  7.25102938e-09 -1.04233547e-08\n",
      "  -1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "  -1.04233547e-08 -2.59447003e-02  2.09632474e-03 -2.66954682e-02\n",
      "  -2.71381719e-03  1.31477254e-03 -3.60038187e-01  1.37204974e-01\n",
      "  -1.18317359e-01 -5.17800125e-02  3.36906575e-02 -5.23712814e-01\n",
      "   1.91278586e-01  8.75273627e-02  2.14991318e-02 -1.61456465e-02\n",
      "   2.96494750e-01 -1.10915466e-01  1.85063392e-01  3.03066787e-02\n",
      "  -3.40836567e-02  3.22893202e-01  8.66123157e-02 -1.19182618e-01\n",
      "   2.69023946e-02  1.12667309e-02 -1.05791576e-08 -1.47213662e-08\n",
      "   7.25102933e-09  7.25102938e-09 -1.04233547e-08 -1.05791576e-08\n",
      "  -1.47213662e-08  7.25102933e-09  7.25102938e-09 -1.04233547e-08\n",
      "  -1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "  -1.04233547e-08 -2.27577910e-01 -2.45045214e-01  1.58213359e-02\n",
      "   1.91329538e-03 -3.04367395e-02  2.34572546e-01 -2.57437797e-01\n",
      "   1.28889457e-01  5.25583363e-02 -5.37762898e-03  5.61227861e-01\n",
      "  -1.84876187e-01 -6.17074611e-02 -1.72538583e-02  1.53552881e-02\n",
      "   1.11015013e-01 -2.92418500e-02 -7.69027769e-02 -1.96220876e-02\n",
      "   1.75836648e-02 -1.05791576e-08 -1.47213662e-08  7.25102933e-09\n",
      "   7.25102938e-09 -1.04233547e-08 -1.05791576e-08 -1.47213662e-08\n",
      "   7.25102933e-09  7.25102938e-09 -1.04233547e-08 -1.05791576e-08\n",
      "  -1.47213662e-08  7.25102933e-09  7.25102938e-09 -1.04233547e-08\n",
      "  -1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "  -1.04233547e-08 -1.05791576e-08 -1.47213662e-08  7.25102933e-09\n",
      "   7.25102938e-09 -1.04233547e-08 -1.05791576e-08 -1.47213662e-08\n",
      "   7.25102933e-09  7.25102938e-09 -1.04233547e-08 -1.05791576e-08\n",
      "  -1.47213662e-08  7.25102933e-09  7.25102938e-09 -1.04233547e-08\n",
      "  -1.05791576e-08 -1.47213662e-08  7.25102933e-09  7.25102938e-09\n",
      "  -1.04233547e-08 -1.05791576e-08 -1.47213662e-08  7.25102933e-09\n",
      "   7.25102938e-09 -1.04233547e-08 -1.05791576e-08 -1.47213662e-08\n",
      "   7.25102933e-09  7.25102938e-09 -1.04233547e-08 -1.05791576e-08\n",
      "  -1.47213662e-08  7.25102933e-09  7.25102938e-09 -1.04233547e-08]]\n"
     ]
    }
   ],
   "source": [
    "#test_feature=block_reduce(test_feature, (1, 4, 4, 1), np.mean).reshape(1,-1)\n",
    "#print('block_reduce輸出格式:',test_feature.shape)\n",
    "#print('block_reduce輸出:',test_feature)\n",
    "\n",
    "def manual_block_reduce(input_array, block_size, func):\n",
    "    # 獲取輸入數據的形狀\n",
    "    batch_size, height, width, channels = input_array.shape\n",
    "    \n",
    "    # 計算新的尺寸\n",
    "    new_height = height // block_size[0]\n",
    "    new_width = width // block_size[1]\n",
    "    \n",
    "    # 初始化結果矩陣\n",
    "    output_array = np.zeros((batch_size, new_height, new_width, channels))\n",
    "    \n",
    "    # 使用切片操作來進行區塊平均\n",
    "    for b in range(batch_size):\n",
    "        for c in range(channels):\n",
    "            for i in range(new_height):\n",
    "                for j in range(new_width):\n",
    "                    # 提取區塊並計算平均\n",
    "                    block = input_array[b, i*block_size[0]:(i+1)*block_size[0], j*block_size[1]:(j+1)*block_size[1], c]\n",
    "                    output_array[b, i, j, c] = func(block)\n",
    "                    \n",
    "    return output_array\n",
    "\n",
    "\n",
    "test_feature = manual_block_reduce(test_feature, (4, 4), np.mean)\n",
    "\n",
    "# 重塑輸出以匹配 (1, -1)\n",
    "test_feature = test_feature.reshape(1, -1)\n",
    "\n",
    "print('block_reduce輸出格式:', test_feature.shape)\n",
    "print('block_reduce輸出:', test_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce88d389-3e3a-4c2f-9a36-f271a9c06956",
   "metadata": {},
   "source": [
    "## 4. 請不使用 test_feature_reduce 函數，也不依賴任何現成的模組，純粹使用數學矩陣運算來推導 test_feature_reduce 的運作邏輯。LAG_UNIT內訓練後有固定的權重可以使用，請藉由這個權重來與test_feature做運算推導出test_festure_reduce。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff53c67e-0220-4b5c-b98b-93487b4c903b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Testing--------\n",
      "LAG_Unit輸出格式 (1, 50)\n",
      "LAG_Unit輸出 [[ 0.00140239 -0.0560488   0.03577215 -0.02654999  0.02321604  0.04560477\n",
      "  -0.04532692  0.04189264  0.07545221 -0.07596422 -0.0048354  -0.06017763\n",
      "   0.07376453  0.04652821  0.02743517  0.19509754  0.11029724  0.06086413\n",
      "  -0.00610494  0.20538763 -0.03458643 -0.04639241 -0.11209536 -0.02925486\n",
      "  -0.03275703  0.18351793  0.13886347  0.0113744   0.22110084  0.01344629\n",
      "   0.01578973  0.07465364 -0.00249271  0.01903881 -0.06956347  0.10972603\n",
      "   0.02091002  0.02731032  0.11292992  0.02480197 -0.01049191 -0.00866659\n",
      "  -0.03323777 -0.00672383 -0.01684828 -0.01189062 -0.09468738 -0.04487295\n",
      "  -0.11369706  0.02116813]]\n",
      "--------Testing--------\n",
      "LAG_Unit輸出格式 (1, 50)\n",
      "LAG_Unit輸出 [[ 0.00140239 -0.0560488   0.03577215 -0.02654999  0.02321604  0.04560477\n",
      "  -0.04532692  0.04189264  0.07545221 -0.07596422 -0.0048354  -0.06017763\n",
      "   0.07376453  0.04652821  0.02743517  0.19509754  0.11029724  0.06086413\n",
      "  -0.00610494  0.20538763 -0.03458643 -0.04639241 -0.11209536 -0.02925486\n",
      "  -0.03275703  0.18351793  0.13886347  0.0113744   0.22110084  0.01344629\n",
      "   0.01578973  0.07465364 -0.00249271  0.01903881 -0.06956347  0.10972603\n",
      "   0.02091002  0.02731032  0.11292992  0.02480197 -0.01049191 -0.00866659\n",
      "  -0.03323777 -0.00672383 -0.01684828 -0.01189062 -0.09468738 -0.04487295\n",
      "  -0.11369706  0.02116813]]\n"
     ]
    }
   ],
   "source": [
    "test_feature_reduce_ori=LAG_Unit(test_feature,train_labels=None, class_list=class_list, SAVE=SAVE,num_clusters=50,alpha=5,Train=False)\n",
    "print('LAG_Unit輸出格式',test_feature_reduce_ori.shape)\n",
    "print('LAG_Unit輸出',test_feature_reduce_ori)\n",
    "import scipy\n",
    "def LAG_Unit_manual(feature,train_labels=None, class_list=None, SAVE=None,num_clusters=50,alpha=5,Train=True):\n",
    "    def Norm(feature): \n",
    "        #   shape:(# sample, # feature)\n",
    "        feature = feature - np.min(feature,1).reshape(-1,1)\n",
    "        feature = feature/np.sum(feature,1).reshape(-1,1)\n",
    "        return feature\n",
    "    def Relu(centroid_old): \n",
    "        #   shape:(# sample, # feature)\n",
    "        centroid_old[centroid_old<0]=0\n",
    "        return centroid_old\n",
    "    def llsr_train(feature_train,labels_train,encode=True,centroid=None,clus_labels=None,train_labels=None,scaler=None, alpha=10):\n",
    "        if encode:\n",
    "            alpha=alpha\n",
    "            print('Alpha:',alpha)\n",
    "    #        labels_train_onehot = encode_onehot(labels_train) \n",
    "            n_sample=labels_train.shape[0]\n",
    "            labels_train_onehot=np.zeros((n_sample,clus_labels.shape[0]))\n",
    "            for i in range(n_sample):\n",
    "                gt=train_labels[i]\n",
    "                idx=clus_labels==gt\n",
    "                dis=euclidean_distances(feature_train[i].reshape(1,-1),centroid[idx]).reshape(-1)\n",
    "                dis=dis/(dis.min()+1e-5)\n",
    "                p_dis=np.exp(-dis*alpha)\n",
    "                p_dis=p_dis/p_dis.sum()\n",
    "                labels_train_onehot[i,idx]=p_dis            \n",
    "        else:     \n",
    "            labels_train_onehot = labels_train \n",
    "        feature_train = scaler.transform(feature_train)\n",
    "        A = np.ones((feature_train.shape[0], 1))\n",
    "        feature_train = np.concatenate((A, feature_train), axis=1)\n",
    "        #    print(np.sort(labels_train_onehot[:10],1)[:,::-1])\n",
    "        weight=scipy.linalg.lstsq(feature_train,labels_train_onehot)[0]       \n",
    "        weight_save = weight[1:weight.shape[0]]\n",
    "        bias_save = weight[0].reshape(1, -1)\n",
    "        return weight_save, bias_save\n",
    "    def llsr_test(feature_test,weight_save,bias_save):\n",
    "        \n",
    "        feature_test=np.matmul(feature_test,weight_save)\n",
    "        feature_test=feature_test+bias_save\n",
    "        return feature_test\n",
    "    \n",
    "    def compute_target_(feature,train_labels,num_clusters,class_list): \n",
    "        use_classes=len(class_list) \n",
    "    \n",
    "        train_labels = train_labels.reshape(-1)\n",
    "        num_clusters_sub = int(num_clusters/use_classes)\n",
    "        batch_size= 1000 \n",
    "        labels = np.zeros((feature.shape[0]))\n",
    "        clus_labels = np.zeros((num_clusters,))\n",
    "        centroid = np.zeros((num_clusters, feature.shape[1]))\n",
    "        for i in range(use_classes):\n",
    "            ID=class_list[i]\n",
    "            feature_train = feature[train_labels==ID]\n",
    "            kmeans = MiniBatchKMeans(n_clusters=num_clusters_sub,batch_size=batch_size).fit(feature_train)\n",
    "    #       kmeans = KMeans(n_clusters=num_clusters_sub).fit(feature_train)\n",
    "            labels[train_labels==ID] = kmeans.labels_ + i*num_clusters_sub\n",
    "            clus_labels[i*num_clusters_sub:(i+1)*num_clusters_sub] = ID\n",
    "            centroid[i*num_clusters_sub:(i+1)*num_clusters_sub] = kmeans.cluster_centers_\n",
    "            print ('FINISH KMEANS', i)\n",
    "            \n",
    "        return labels, clus_labels.astype(int),centroid\n",
    "    \n",
    "    def encode_onehot(a):\n",
    "        a = a.reshape(-1)\n",
    "        print ('before encode shape:', a.shape)\n",
    "        b = np.zeros((a.shape[0],1+ int(a.max())))# - 1./a.max()\n",
    "        b[np.arange(a.shape[0]), a] = 1\n",
    "        print ('after encode shape:', b.shape)\n",
    "        return b.astype(float)\n",
    "\n",
    "    \n",
    "    if Train:      \n",
    "        print('--------Train LAG Unit--------')    \n",
    "        print ('feature_train shape:', feature.shape)\n",
    "        use_classes=len(np.unique(train_labels)) \n",
    "        k=0                        \n",
    "        # Compute output features       \n",
    "        labels_train,clus_labels,centroid = compute_target_(feature,train_labels,num_clusters,class_list)    \n",
    "        \n",
    "        scaler=preprocessing.StandardScaler().fit(feature)  \n",
    "        weight_save,bias_save=llsr_train(feature,labels_train.astype(int),encode=True,centroid=centroid,\n",
    "                                         clus_labels=clus_labels,train_labels=train_labels,\n",
    "                                         scaler=scaler,alpha=alpha)\n",
    "        \n",
    "        SAVE[str(k)+' clus_labels'] = clus_labels\n",
    "        SAVE[str(k)+' LLSR weight'] = weight_save\n",
    "        SAVE[str(k)+' LLSR bias'] = bias_save\n",
    "        SAVE[str(k)+' scaler'] = scaler\n",
    "        print('weight',weight_save.shape)\n",
    "        print('bias',bias_save.shape)\n",
    "        feature = llsr_test(scaler.transform(feature),weight_save,bias_save)\n",
    "        pred_labels = np.zeros((feature.shape[0],use_classes))\n",
    "        for km_i in range(use_classes):\n",
    "            pred_labels[:,km_i]=feature[:,clus_labels==km_i].sum(1)\n",
    "        pred_labels = np.argmax(pred_labels, axis=1)\n",
    "        idx = pred_labels == train_labels.reshape(-1)\n",
    "        print(k, ' Kmean training acc is: {}'.format(1.*np.count_nonzero(idx)/train_labels.shape[0]))\n",
    "        return feature\n",
    "    else:\n",
    "        print('--------Testing--------')\n",
    "        k=0\n",
    "        scaler=SAVE[str(k)+' scaler']\n",
    "        feature_reduced =llsr_test(scaler.transform(feature),SAVE[str(k)+' LLSR weight'],SAVE[str(k)+' LLSR bias'])\n",
    "        return feature_reduced      \n",
    "        \n",
    "test_feature_reduce=LAG_Unit_manual(test_feature,train_labels=None, class_list=class_list,SAVE=SAVE,num_clusters=50,alpha=5,Train=False)\n",
    "print('LAG_Unit輸出格式',test_feature_reduce.shape)\n",
    "print('LAG_Unit輸出',test_feature_reduce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb750a13-be31-4144-b9eb-8c7ac5b45217",
   "metadata": {},
   "source": [
    "## 5. 請不使用 clf 函數，也不依賴任何現成的模組，純粹使用數學矩陣運算來推導 clf 的運作邏輯。clf內訓練後有固定的權重可以使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09a394ce-991f-4e4a-af74-f6341b5bfd1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#x=clf.predict(feature_test)\n",
    "class MyLinearSVM:\n",
    "    def __init__(self, learning_rate=0.01, lambda_reg=0.01, num_iters=1000):\n",
    "        \"\"\"\n",
    "        初始化簡化的線性支持向量機分類器\n",
    "        :param learning_rate: 學習率\n",
    "        :param lambda_reg: 正則化參數\n",
    "        :param num_iters: 梯度下降的迭代次數\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.num_iters = num_iters\n",
    "        self.weights = None\n",
    "        self.bias = 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        訓練 Linear SVM 模型\n",
    "        :param X: 訓練數據 (N, D)，N 是樣本數，D 是特徵數\n",
    "        :param y: 標籤 (N,)，值應該是 -1 或 1\n",
    "        \"\"\"\n",
    "        num_samples, num_features = X.shape\n",
    "        self.weights = np.zeros(num_features)  # 初始化權重\n",
    "\n",
    "        # 標籤應該為 -1 或 1\n",
    "        y = np.where(y <= 0, -1, 1)\n",
    "\n",
    "        for _ in range(self.num_iters):\n",
    "            # 計算線性得分\n",
    "            scores = np.dot(X, self.weights) + self.bias\n",
    "            margins = y * scores\n",
    "\n",
    "            # 梯度計算\n",
    "            dw = np.zeros(num_features)\n",
    "            db = 0\n",
    "\n",
    "            for i in range(num_samples):\n",
    "                if margins[i] < 1:\n",
    "                    dw += -y[i] * X[i]\n",
    "                    db += -y[i]\n",
    "\n",
    "            dw = dw / num_samples + self.lambda_reg * self.weights\n",
    "            db = db / num_samples\n",
    "\n",
    "            # 更新權重和偏置\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        使用訓練好的模型進行分類預測\n",
    "        :param X: 測試數據 (N, D)\n",
    "        :return: 預測標籤 (N,)，值為 -1 或 1\n",
    "        \"\"\"\n",
    "        scores = np.dot(X, self.weights) + self.bias\n",
    "        return np.sign(scores)  # 返回標籤 -1 或 1\n",
    "\n",
    "\n",
    "class my_SVC:\n",
    "    def __init__(self, learning_rate=0.01, lambda_reg=0.01, num_iters=1000):\n",
    "        \"\"\"\n",
    "        多類分類的線性 SVM\n",
    "        :param learning_rate: 學習率\n",
    "        :param lambda_reg: 正則化參數\n",
    "        :param num_iters: 梯度下降的迭代次數\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.num_iters = num_iters\n",
    "        self.models = {}  # 每個類別對應一個二分類器\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        訓練 One-vs-All 多類分類器\n",
    "        :param X: 訓練數據 (N, D)\n",
    "        :param y: 標籤 (N,)\n",
    "        \"\"\"\n",
    "        classes = np.unique(y)  # 找到所有的類別\n",
    "        for c in classes:\n",
    "            # 創建二分類標籤，將當前類別設為 1，其餘類別設為 -1\n",
    "            binary_labels = np.where(y == c, 1, -1)\n",
    "\n",
    "            # 訓練二分類器\n",
    "            svm = MyLinearSVM(learning_rate=self.learning_rate, lambda_reg=self.lambda_reg, num_iters=self.num_iters)\n",
    "            svm.fit(X, binary_labels)\n",
    "            self.models[c] = svm\n",
    "\n",
    "        return self  # 返回訓練好的模型以支持鏈式調用\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        使用多類分類器進行預測\n",
    "        :param X: 測試數據 (M, D)\n",
    "        :return: 預測標籤 (M,)\n",
    "        \"\"\"\n",
    "        scores = {}\n",
    "        for c, svm in self.models.items():\n",
    "            scores[c] = np.dot(X, svm.weights) + svm.bias  # 每類別的分數\n",
    "\n",
    "        # 找到每個樣本得分最高的類別\n",
    "        scores_matrix = np.array([scores[c] for c in self.models.keys()]).T  # (M, num_classes)\n",
    "        predictions = np.argmax(scores_matrix, axis=1)  # 返回分數最大的類別\n",
    "        return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2591b9b4-ae90-4503-a98f-ea28803055c4",
   "metadata": {},
   "source": [
    "## 6. 組合以上寫好的部分，自行定義一個自己手刻的pixelhop model，在將test_images丟入計算準確率是否與題目的準確率相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc53c264-27ee-4740-b2c3-fd9fc649e762",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: 1000 32 32 1\n",
      "------------------- Start: PixelHop_8_Neighbour\n",
      "       <Info>        Input feature shape: 1000\n",
      "       <Info>        dilate: 1\n",
      "       <Info>        padding: reflect\n",
      "       <Info>        Output feature shape: 1000\n",
      "------------------- End: PixelHop_8_Neighbour -> using   7.765997 seconds\n",
      "Feature shape: 1000 32 32 9\n",
      "------------------- Start: Saab transformation\n",
      "       <Info>        pixelhop_feature.shape: (1000, 32, 32, 9)\n",
      "       <Info>        training_data.shape: (1024000, 9)\n",
      "       <Info>        Num of kernels: 5\n",
      "       <Info>        Energy percent: 0.941525\n",
      "       <Info>        Sample patches shape after flatten: (1024000, 9)\n",
      "       <Info>        Kernel shape: (5, 9)\n",
      "       <Info>        Transformed shape: (1024000, 5)\n",
      "       <Info>        Save pca params as name: ../weight/pixelhop1_mnist.pkl\n",
      "------------------- End: Saab transformation -> using   0.360000 seconds\n",
      "------------------- Start: Pixelhop_fit\n",
      "       <Info>        Using weight: ../weight/pixelhop1_mnist.pkl\n",
      "       <Info>        Transformed feature shape: (1000, 32, 32, 5)\n",
      "------------------- End: Pixelhop_fit -> using   0.045000 seconds\n",
      "--------Train LAG Unit--------\n",
      "feature_train shape: (1000, 1280)\n",
      "FINISH KMEANS 0\n",
      "FINISH KMEANS 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoyo2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n",
      "C:\\Users\\yoyo2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n",
      "C:\\Users\\yoyo2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISH KMEANS 2\n",
      "FINISH KMEANS 3\n",
      "FINISH KMEANS 4\n",
      "FINISH KMEANS 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoyo2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n",
      "C:\\Users\\yoyo2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n",
      "C:\\Users\\yoyo2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n",
      "C:\\Users\\yoyo2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISH KMEANS 6\n",
      "FINISH KMEANS 7\n",
      "FINISH KMEANS 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoyo2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n",
      "C:\\Users\\yoyo2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n",
      "C:\\Users\\yoyo2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISH KMEANS 9\n",
      "Alpha: 5\n",
      "weight (1280, 50)\n",
      "bias (1, 50)\n",
      "0  Kmean training acc is: 0.986\n",
      "Feature shape: 500 32 32 1\n",
      "------------------- Start: PixelHop_8_Neighbour\n",
      "       <Info>        Input feature shape: 500\n",
      "       <Info>        dilate: 1\n",
      "       <Info>        padding: reflect\n",
      "       <Info>        Output feature shape: 500\n",
      "------------------- End: PixelHop_8_Neighbour -> using   4.015002 seconds\n",
      "Feature shape: 500 32 32 9\n",
      "------------------- Start: Pixelhop_fit\n",
      "       <Info>        Using weight: ../weight/pixelhop1_mnist.pkl\n",
      "       <Info>        Transformed feature shape: (500, 32, 32, 5)\n",
      "------------------- End: Pixelhop_fit -> using   0.015000 seconds\n",
      "--------Testing--------\n",
      "***** Train ACC: 0.99\n",
      "***** Test ACC: 0.988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import scipy\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "train_images, train_labels, test_images, test_labels, class_list = import_data_mnist(\"0-9\")  \n",
    "N_train=1000\n",
    "N_test=500\n",
    "SAVE={}\n",
    "train_images=train_images[:N_train]\n",
    "train_labels=train_labels[:N_train]\n",
    "test_images=train_images[:N_test]\n",
    "test_labels=train_labels[:N_test]\n",
    "\n",
    "train_feature=PixelHop_Unit_manual(train_images, dilate=1, pad='reflect', num_AC_kernels=5, weight_name='pixelhop1_mnist.pkl', getK=1)\n",
    "train_feature = manual_block_reduce(train_feature, (1, 4, 4, 1), np.mean).reshape(N_train,-1)\n",
    "train_feature_reduce=LAG_Unit_manual(train_feature,train_labels=train_labels, class_list=class_list, SAVE=SAVE,num_clusters=50,alpha=5,Train=True)\n",
    "\n",
    "test_feature=PixelHop_Unit_manual(test_images, dilate=1, pad='reflect', num_AC_kernels=5, weight_name='pixelhop1_mnist.pkl', getK=0)\n",
    "test_feature=manual_block_reduce(test_feature, (1, 4, 4, 1), np.mean).reshape(N_test,-1)\n",
    "test_feature_reduce=LAG_Unit_manual(test_feature,train_labels=None, class_list=class_list, SAVE=SAVE,num_clusters=50,alpha=5,Train=False)\n",
    "\n",
    "# 計算訓練資料的平均值和標準差\n",
    "mean = np.mean(train_feature_reduce, axis=0)\n",
    "std = np.std(train_feature_reduce, axis=0)\n",
    "\n",
    "# 標準化訓練資料\n",
    "feature = (train_feature_reduce - mean) / std\n",
    "\n",
    "# 使用相同的均值和標準差標準化測試資料\n",
    "feature_test = (test_feature_reduce - mean) / std\n",
    "clf_manual = my_SVC(learning_rate=0.01, lambda_reg=0.01, num_iters=1000)\n",
    "clf_manual.fit(feature, train_labels)\n",
    "\n",
    "print('***** Train ACC:', accuracy_score(train_labels,clf_manual.predict(feature)))\n",
    "print('***** Test ACC:', accuracy_score(test_labels,clf_manual.predict(feature_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64906984-100c-4a99-8878-83cafa488dec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
